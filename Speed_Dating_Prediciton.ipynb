{"cells":[{"cell_type":"markdown","source":["# Problem Formulation\n","\n","The problem at hand is to predict the outcome of a specific speed dating seccion based on the profiles of the two participants in such session. The input for the model will be tabular data containing attributes such as age, gender, income, etc. This data is both categorical and continuous, further processing will be conducting to process these different data types. \n","\n","The output of the model will be a discrete prediction of the outcome of the speed dating session being either a 1 (successful) or 2(unsuccessful). This a classificaiton problem and the required data mining fuction.\n","\n","The main challenge presented by this problem is dealing with the imbalance in the dataset and the large amount of missing vlaues. To handle the imbalance issue sampling techniques and or data augmentation. To handle the missing vlaues different imputation methods will be explored. \n","\n","The impact of this problem, is to help individuals better find dating partners and for dating companies to find trends that may indicate good matches. \n","\n","\n","The ideal solution to this problem is a model that can correctly predict the outcome of a speed dating session with a high accuracy while maintaining a high degree of generalizability. The model must be genrilizable so that it can not only work with speed dating but other dating applicaitons."],"metadata":{"id":"5sNpbLq-u5Rf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzB1NsPNNlB8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score\n","from pprint import pprint\n","import matplotlib.pyplot as plt\n","from xgboost import XGBRegressor\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKbRoYwbeA3P","executionInfo":{"status":"ok","timestamp":1666621113134,"user_tz":240,"elapsed":23051,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"be292445-e00e-4371-ee99-8cbab4d00121"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lHKFApu57nH","executionInfo":{"status":"ok","timestamp":1666505792950,"user_tz":240,"elapsed":351,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"44a3649c-ac04-43e1-ba6d-a3880b56902b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Oct 23 06:16:32 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mm_E40l1NlB9","executionInfo":{"status":"ok","timestamp":1666621119384,"user_tz":240,"elapsed":3347,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"daef471e-84ef-4c48-8e0e-c5b18d696a25"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5909, 192)"]},"metadata":{},"execution_count":3}],"source":["data = pd.read_csv('/content/gdrive/MyDrive/train_A2.csv')\n","data_test = pd.read_csv('/content/gdrive/MyDrive/test_A2.csv')\n","data.shape"]},{"cell_type":"code","source":["data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"lWxQyNubOmCD","executionInfo":{"status":"ok","timestamp":1666621120752,"user_tz":240,"elapsed":6,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"56d2d7e8-5102-4e2a-d449-60333a0af039"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n","0       0    3       2    14     18         2       2.0     14       12   \n","1       1   14       1     3     10         2       NaN      8        8   \n","2       1   14       1    13     10         8       8.0     10       10   \n","3       1   38       2     9     20        18      13.0      6        7   \n","4       1   24       2    14     20         6       6.0     20       17   \n","\n","     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n","0  372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n","1   63.0  ...      8.0       8.0     7.0     8.0      NaN      NaN       NaN   \n","2  331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n","3  200.0  ...      9.0       8.0     8.0     6.0      NaN      NaN       NaN   \n","4  357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n","\n","   fun5_3  amb5_3    id  \n","0     NaN     NaN  2583  \n","1     NaN     NaN  6830  \n","2     NaN     NaN  4840  \n","3     NaN     NaN  5508  \n","4     NaN     NaN  4828  \n","\n","[5 rows x 192 columns]"],"text/html":["\n","  <div id=\"df-3841afcb-2def-4ab4-b23a-320d80fed765\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gender</th>\n","      <th>idg</th>\n","      <th>condtn</th>\n","      <th>wave</th>\n","      <th>round</th>\n","      <th>position</th>\n","      <th>positin1</th>\n","      <th>order</th>\n","      <th>partner</th>\n","      <th>pid</th>\n","      <th>...</th>\n","      <th>sinc3_3</th>\n","      <th>intel3_3</th>\n","      <th>fun3_3</th>\n","      <th>amb3_3</th>\n","      <th>attr5_3</th>\n","      <th>sinc5_3</th>\n","      <th>intel5_3</th>\n","      <th>fun5_3</th>\n","      <th>amb5_3</th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>14</td>\n","      <td>12</td>\n","      <td>372.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2583</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>63.0</td>\n","      <td>...</td>\n","      <td>8.0</td>\n","      <td>8.0</td>\n","      <td>7.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>6830</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>8.0</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>331.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4840</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>38</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>13.0</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>200.0</td>\n","      <td>...</td>\n","      <td>9.0</td>\n","      <td>8.0</td>\n","      <td>8.0</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5508</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>20</td>\n","      <td>6</td>\n","      <td>6.0</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>357.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4828</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 192 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3841afcb-2def-4ab4-b23a-320d80fed765')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3841afcb-2def-4ab4-b23a-320d80fed765 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3841afcb-2def-4ab4-b23a-320d80fed765');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["print(data.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOKaCFa-4ufw","executionInfo":{"status":"ok","timestamp":1666621124772,"user_tz":240,"elapsed":302,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"96031da3-7374-4e45-842d-5dc3fdae75fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['gender', 'idg', 'condtn', 'wave', 'round', 'position', 'positin1',\n","       'order', 'partner', 'pid',\n","       ...\n","       'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3', 'attr5_3', 'sinc5_3',\n","       'intel5_3', 'fun5_3', 'amb5_3', 'id'],\n","      dtype='object', length=192)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"-KchmQbrNlB9","executionInfo":{"status":"ok","timestamp":1666621125208,"user_tz":240,"elapsed":2,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"4c2a387b-3557-4f33-fc27-331c57296568"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f6eb1834c50>"]},"metadata":{},"execution_count":6},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["data.isnull().sum().hist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"E_vzRu0JNlB9","executionInfo":{"status":"ok","timestamp":1666621128996,"user_tz":240,"elapsed":411,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"999378d5-5f44-4d6c-b7f7-da29af17e0e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f6eb18e29d0>"]},"metadata":{},"execution_count":7},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["data['match'].hist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrfthP61NlB-","executionInfo":{"status":"ok","timestamp":1666621139750,"user_tz":240,"elapsed":8812,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"d63176b5-b66e-4235-c8b6-84bd9c8ec731"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-optimize\n","  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n","\u001b[K     |████████████████████████████████| 100 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.7.3)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.2.0)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n","Collecting pyaml>=16.9\n","  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n","Installing collected packages: pyaml, scikit-optimize\n","Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"]}],"source":["# if you haven't installed xgboost on your system, uncomment the line below\n","!pip install xgboost\n","# if you haven't installed bayesian-optimization on your system, uncomment the line below\n","!pip install scikit-optimize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tsXWsVmPNlB-"},"outputs":[],"source":["x = data.drop('match', axis=1)\n","features_numeric = list(x.select_dtypes(include=['float64']))\n","features_categorical = list(x.select_dtypes(include=['object']))\n","y = data['match']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41oHaJ_ZNlB-","executionInfo":{"status":"ok","timestamp":1666621144884,"user_tz":240,"elapsed":4,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"7069b650-7884-4a5d-aa59-46abb68db8a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income', 'career']\n"]}],"source":["print(features_categorical)"]},{"cell_type":"code","source":["# All required lybrary for this project\n","import numpy as np\n","from sklearn.compose import ColumnTransformer\n","from sklearn.datasets import fetch_openml\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from xgboost.sklearn import XGBClassifier\n","from sklearn.impute import KNNImputer\n","from imblearn.over_sampling import SMOTE\n","from imblearn.pipeline import Pipeline as imbpipeline\n","from sklearn.model_selection import StratifiedKFold\n","from skopt.space import Real, Categorical, Integer\n","from skopt import BayesSearchCV\n","from scipy.stats import randint as sp_randInt\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier"],"metadata":{"id":"_VEGiTKqwq7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0H_gloOhvgK","executionInfo":{"status":"ok","timestamp":1666640730750,"user_tz":240,"elapsed":20277,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"7a78709f-bc5b-45f3-89b1-6a1a94dc7b87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vksgddW4NlB-","executionInfo":{"status":"ok","timestamp":1666277899017,"user_tz":240,"elapsed":168588,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"9c205e76-680e-4190-d1bf-509d71569a5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.994, test=0.855) total time=   3.2s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.992, test=0.852) total time=   2.1s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.994, test=0.833) total time=   1.1s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.990, test=0.828) total time=   1.2s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.989, test=0.833) total time=   1.1s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.860) total time=   1.9s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.867) total time=   2.3s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.849) total time=   1.9s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.998, test=0.842) total time=   3.9s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.998, test=0.849) total time=   3.5s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.882) total time=   7.9s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.891) total time=   8.2s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.883) total time=   8.1s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.863) total time=   8.3s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.875) total time=   8.3s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.852) total time=   1.8s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.998, test=0.840) total time=   1.9s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.998, test=0.823) total time=   2.1s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.997, test=0.840) total time=   2.2s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.997, test=0.804) total time=   2.4s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.865) total time=   3.2s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.866) total time=   3.3s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.848) total time=   3.1s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.849) total time=   3.3s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.843) total time=   4.0s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.880) total time=  11.9s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.890) total time=  11.6s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.881) total time=  11.1s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.865) total time=  11.5s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.877) total time=  11.5s\n","best score 0.8789401909943632\n","best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 100, 'preprocessor__num__imputer__strategy': 'mean'}\n"]}],"source":["np.random.seed(0)\n","\n","# the following pipeline is the standard for all following trails, the comments\n","# in this cell will apply for all following trails in cases where nothing changes\n","\n","transformer_numeric = Pipeline( # transforms for numeric values in dataset\n","    steps=[\n","        ('imputer', SimpleImputer(strategy='median')), # missing value replacment with median value as the defualt\n","        ('scaler', StandardScaler())] # Standardize the feature set by removing the mean and scaling to unit variance.\n",")\n","\n","transformer_categorical = Pipeline( # transforms for categorical values in dataset\n","    steps=[\n","        # missing value replacment with a constant value as the defualt\n","        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), \n","        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","        # encode all the categorical values with binary values\n","    ]\n",")\n","\n","# Apply the above numeric and categgorical transformations to the whole dataset(dataframe)\n","preprocessor = ColumnTransformer( \n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","# Create a sklearn pipeline and complie the required steps\n","full_pipline = Pipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('my_classifier', XGBClassifier( # XGBoost the claddifier being used in this pipeline\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","# prepare parameters and their possible values for the following gridsearch\n","param_grid = {\n","    'preprocessor__num__imputer__strategy': ['mean'],\n","    'my_classifier__n_estimators': [10, 20, 100],\n","    'my_classifier__max_depth':[10, 20]\n","}\n","\n","# Gridsearch with 5 k-fold validation\n","grid_search = GridSearchCV(\n","    full_pipline, param_grid, cv=5, verbose=3, n_jobs=1, \n","    scoring='roc_auc',return_train_score=True)\n","\n","grid_search.fit(x, y)\n","\n","print('best score {}'.format(grid_search.best_score_))\n","print('best score {}'.format(grid_search.best_params_))"]},{"cell_type":"code","source":["df_results = pd.DataFrame(grid_search.cv_results_)\n","print(df_results['mean_train_score'].tolist)\n","print(df_results['mean_test_score'].tolist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUNmT7vPILzn","executionInfo":{"status":"ok","timestamp":1666277978477,"user_tz":240,"elapsed":130,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"73634b17-2b6f-4fe3-b6aa-4cc9c2a04778"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method IndexOpsMixin.tolist of 0    0.991696\n","1    0.998603\n","2    1.000000\n","3    0.998035\n","4    0.999912\n","5    1.000000\n","Name: mean_train_score, dtype: float64>\n","<bound method IndexOpsMixin.tolist of 0    0.840206\n","1    0.853616\n","2    0.878940\n","3    0.831784\n","4    0.853915\n","5    0.878682\n","Name: mean_test_score, dtype: float64>\n"]}]},{"cell_type":"markdown","source":["# Trial 1\n"," \n","reason for change?\n"," \n","To build on the work done in trial 0, and to address the issue of missing values a KNN imputer will be used in trail 1. In trial 0, missing vlaues were replaced with either the mean value for numeric values or constants for categorical values. KNN imputer works by replacing missing values with the mean of the missing values n nearest neighbors. This will create a more representative replacement value.\n"," \n","*Note, applying a KNNImputer to categorical features presents an issue. When you one hot encoded your categorical data, the missing values will be encoded into new binary values and thus no longer be missing values. For categorical values the most frequent imputer method will be used to hopefully generate better results than replacing with constant.  \n"," \n","expected outcome?\n"," \n","I expect the performance of the model to improve, as the replacement of missing values using KNN imputation should generate a dataset that is more representative of the relationships between features. The overfitting problem will most likely still be present as the issue of imbalance in the dataset has not yet been addressed. \n"],"metadata":{"id":"2o9u6OF8Kr_y"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665674588483,"user_tz":240,"elapsed":1577095,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"3006b06f-28c0-443f-8c89-fd246f21c96f","id":"Jlx2doM6PxTc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.994, test=0.830) total time=  22.5s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.995, test=0.828) total time=  24.2s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.995, test=0.812) total time=  25.6s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.988, test=0.824) total time=  25.0s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.989, test=0.826) total time=  23.1s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.999, test=0.848) total time=  26.6s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=1.000, test=0.841) total time=  27.0s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.999, test=0.839) total time=  27.7s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.998, test=0.839) total time=  31.6s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.999, test=0.847) total time=  30.2s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.874) total time=  39.0s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.869) total time=  38.3s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.868) total time=  32.1s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.856) total time=  32.9s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.874) total time=  31.6s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.999, test=0.835) total time=  27.9s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.998, test=0.817) total time=  27.7s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.999, test=0.806) total time=  27.4s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.998, test=0.812) total time=  31.7s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.998, test=0.814) total time=  25.8s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.859) total time=  29.1s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.839) total time=  29.6s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.830) total time=  27.6s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.826) total time=  28.2s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.823) total time=  26.7s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.877) total time=  36.3s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.870) total time=  36.0s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.868) total time=  35.6s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.858) total time=  36.0s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.865) total time=  33.9s\n","best score 0.8679986418483383\n","best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 100}\n"]}],"source":["np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', KNNImputer(n_neighbors=2)), #KNNImputer using n = 2 for nearest neighbours \n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing')) # change to most frequent replacement instead of constant\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","full_pipline = Pipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('my_classifier', XGBClassifier(\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","param_grid = {\n","    'my_classifier__n_estimators': [10, 20, 100],\n","    'my_classifier__max_depth':[10, 20]\n","}\n","\n","grid_search = GridSearchCV(\n","    full_pipline, param_grid, cv=5, verbose=3, n_jobs=1, \n","    scoring='roc_auc',return_train_score=True)\n","\n","grid_search.fit(x, y)\n","\n","print('best score {}'.format(grid_search.best_score_))\n","print('best score {}'.format(grid_search.best_params_))"]},{"cell_type":"code","source":["df_results = pd.DataFrame(grid_search.cv_results_)\n","print(df_results['mean_train_score'].tolist)\n","print(df_results['mean_test_score'].tolist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8z5PvIsLpXl6","executionInfo":{"status":"ok","timestamp":1665602519316,"user_tz":240,"elapsed":5,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"198a84a3-c26c-4995-a90d-26407c777d9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method IndexOpsMixin.tolist of 0    0.992249\n","1    0.999098\n","2    1.000000\n","3    0.998472\n","4    0.999947\n","5    1.000000\n","Name: mean_train_score, dtype: float64>\n","<bound method IndexOpsMixin.tolist of 0    0.823932\n","1    0.842706\n","2    0.867999\n","3    0.816920\n","4    0.835567\n","5    0.867469\n","Name: mean_test_score, dtype: float64>\n"]}]},{"cell_type":"markdown","source":["###thoughts and observations for trial 1\n","\n","Unexpectedly the performance did not improve, there was a very slight decrease in performance. This technique of imputation is a lot more computationally expensive although I do think it will still provide performance improvements with further changes. There is still signs of overfitting with the near perfect training accuracy and worse validation/test accuracy. \n","\n","###plan for trial 2\n","\n","The next plan of attack is to address the imbalance in the training data by implementing SMOTE. I will continue to use the KNNImputer as i still believe it is a more accurate way to fill missing values. I will compare the results using SMOTE with KNNImputer and SMOTE with simple imputation to see if the KNNimputer really does not increase the performance of the model. \n","\n"],"metadata":{"id":"l-WPk9jLpLpB"}},{"cell_type":"markdown","source":["# Trial 2\n"," \n","reason for change?\n","\n","The used classifier XGBoost is a boosting algorithm which applied regularization techniques to reduce overfitting, although there is some slight overfitting observed. The observation is that there is near perfect training accuracy, while lesser validation/test accuracy. To further help with overfitting, the issue of imbalance in the dataset needs to be addressed. Synthetic Minority Oversmapling Technique (SMOTE) is a technique that works to increase the number of instances of the minority class in an imbalanced dataset.\n","\n","Stratisfied k fold cross validaiton will be used to maintain this rebalance in class representaiton throughout all folds. \n","\n","The model will be trained once with KNNImputer and once with simple imputation, to see if if the KNNimputer really does not increase the perforamnce of the model. \n","\n","expected outcome?\n","\n","By creating a more balanced dataset the model should be able to have increased test accuracy as the training rounds are now seeing more occasions of the minority class. \n"],"metadata":{"id":"CrYAF0Yb3kr9"}},{"cell_type":"code","source":["np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', KNNImputer(n_neighbors=2)),\n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing'))\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","full_pipline = imbpipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('smote',SMOTE(random_state=11)), #add SMOTE to the pipeline steps\n","        ('my_classifier', XGBClassifier(\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","stratisfied_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\n","                                       \n","\n","param_grid = {\n","    'my_classifier__n_estimators': [10, 20, 100],\n","    'my_classifier__max_depth':[10, 20]\n","}\n","\n","grid_search = GridSearchCV(\n","    full_pipline, param_grid, cv=stratisfied_kfold, verbose=3, n_jobs=1, \n","    scoring='roc_auc',return_train_score=True)\n","\n","grid_search.fit(x, y)\n","\n","print('best score {}'.format(grid_search.best_score_))\n","print('best score {}'.format(grid_search.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTxSa-s9-vLJ","executionInfo":{"status":"ok","timestamp":1665677253734,"user_tz":240,"elapsed":1724288,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"0dc59723-db11-405d-dcaa-f056acba065a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.969, test=0.814) total time=  26.9s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.971, test=0.821) total time=  27.1s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.973, test=0.844) total time=  28.3s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.964, test=0.829) total time=  26.0s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10;, score=(train=0.973, test=0.833) total time=  25.6s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.993, test=0.829) total time=  30.0s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.995, test=0.840) total time=  30.2s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.993, test=0.861) total time=  30.2s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.993, test=0.846) total time=  30.1s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20;, score=(train=0.994, test=0.846) total time=  28.3s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.862) total time=  42.8s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.863) total time=  42.3s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.885) total time=  42.4s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.863) total time=  41.2s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100;, score=(train=1.000, test=0.863) total time=  39.3s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.992, test=0.819) total time=  29.5s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.996, test=0.815) total time=  29.0s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.996, test=0.838) total time=  27.2s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.994, test=0.825) total time=  27.8s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10;, score=(train=0.998, test=0.823) total time=  27.0s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=0.999, test=0.832) total time=  32.3s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.832) total time=  32.3s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.852) total time=  32.5s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=0.999, test=0.848) total time=  32.4s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20;, score=(train=1.000, test=0.838) total time=  30.1s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.859) total time=  48.1s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.858) total time=  48.4s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.879) total time=  47.5s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.864) total time=  50.2s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100;, score=(train=1.000, test=0.863) total time=  47.5s\n","best score 0.8673728572952948\n","best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 100}\n"]}]},{"cell_type":"code","source":["df_results = pd.DataFrame(grid_search.cv_results_)\n","print(df_results['mean_train_score'].tolist)\n","print(df_results['mean_test_score'].tolist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_6QkIm8IeaC","executionInfo":{"status":"ok","timestamp":1665677782996,"user_tz":240,"elapsed":293,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"97d99f27-952c-463e-8ee1-dd288d589a3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method IndexOpsMixin.tolist of 0    0.970011\n","1    0.993531\n","2    1.000000\n","3    0.995219\n","4    0.999641\n","5    1.000000\n","Name: mean_train_score, dtype: float64>\n","<bound method IndexOpsMixin.tolist of 0    0.828154\n","1    0.844536\n","2    0.867373\n","3    0.824090\n","4    0.840403\n","5    0.864614\n","Name: mean_test_score, dtype: float64>\n"]}]},{"cell_type":"code","source":["np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', SimpleImputer(strategy='median')), # now using simple imputation to see if KNN imputation really does not perform any better\n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing'))\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","# need to use imblearn pipeline, since SMOTE doesn’t have a ‘fit_transform’ method\n","# thus cannot use it with ‘Scikit-Learn’ pipeline.\n","\n","full_pipline = imbpipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('smote',SMOTE(random_state=11)),\n","        ('my_classifier', XGBClassifier(\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","stratisfied_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\n","                                       \n","param_grid = {\n","    'preprocessor__num__imputer__strategy': ['mean'],\n","    'my_classifier__n_estimators': [10, 20, 100],\n","    'my_classifier__max_depth':[10, 20]\n","}\n","\n","grid_search_final_simple = GridSearchCV(\n","    full_pipline, param_grid, cv=stratisfied_kfold, verbose=3, n_jobs=1, \n","    scoring='roc_auc',return_train_score=True)\n","\n","grid_search_final_simple.fit(x, y)\n","\n","print('best score {}'.format(grid_search_final_simple.best_score_))\n","print('best score {}'.format(grid_search_final_simple.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lad2dCXRJv_I","executionInfo":{"status":"ok","timestamp":1666380194458,"user_tz":240,"elapsed":353566,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"e5e5f19b-a05f-401f-afac-8fbea209e4e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.975, test=0.831) total time=   2.7s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.975, test=0.832) total time=   2.7s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.972, test=0.866) total time=   2.6s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.970, test=0.846) total time=   2.7s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.972, test=0.844) total time=   2.7s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.994, test=0.857) total time=   4.4s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.994, test=0.855) total time=   4.3s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.991, test=0.876) total time=   4.2s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.991, test=0.861) total time=   4.4s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=0.993, test=0.857) total time=   4.4s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.879) total time=  21.4s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.880) total time=  22.2s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.887) total time=  21.5s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.874) total time=  17.8s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.878) total time=  18.0s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.996, test=0.815) total time=   4.5s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.996, test=0.818) total time=   4.4s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.996, test=0.848) total time=   4.4s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.996, test=0.830) total time=   4.4s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.997, test=0.829) total time=   4.3s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.842) total time=   7.7s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.842) total time=   8.0s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.865) total time=   7.5s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.849) total time=   8.3s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=20, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.843) total time=   8.1s\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.880) total time=  25.2s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  26.1s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.887) total time=  25.2s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  25.6s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  25.2s\n","best score 0.8795950960492078\n","best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 100, 'preprocessor__num__imputer__strategy': 'mean'}\n"]}]},{"cell_type":"code","source":["df_results = pd.DataFrame(grid_search.cv_results_)\n","print(df_results['mean_train_score'].tolist)\n","print(df_results['mean_test_score'].tolist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JX7X_gTLRol","executionInfo":{"status":"ok","timestamp":1665678516740,"user_tz":240,"elapsed":345,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"bdbcffad-feac-4264-de2c-ef87b8b67164"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<bound method IndexOpsMixin.tolist of 0    0.972818\n","1    0.992497\n","2    1.000000\n","3    0.996173\n","4    0.999778\n","5    1.000000\n","Name: mean_train_score, dtype: float64>\n","<bound method IndexOpsMixin.tolist of 0    0.843878\n","1    0.861325\n","2    0.879595\n","3    0.827823\n","4    0.848299\n","5    0.876066\n","Name: mean_test_score, dtype: float64>\n"]}]},{"cell_type":"markdown","source":["###thoughts and observations for trial 2\n","\n","Simple imputation \n","- trial 0: best score 0.8789401909943632 (no SMOTE)\n","- trial 2: best score 0.8795950960492078 (SMOTE)\n","\n","KNNimputer \n","- trial 0: best score 0.8679986418483383 (no SMOTE)\n","- trial 2: best score 0.8673728572952948 (SMOTE)\n","\n","As you can see the SMOTE method for balancing the dataset Unexpectedly does not improve the test accuracy by any significant amount. The second observation is that indeed simple imputation method produces better results than the KNNimputer method. Moving forward the simple imputation method will be used. The very slight improvement from the addition of SMOTE is still relevant and thus will be continuously used in the following trials.\n","\n","###plan for trial 3\n","\n","The next two trials will be used to test the effect of both random search and bayesian search on the performance of the model and associated computation time. To be consistent and best see the effects of the different search algorithms the same configurations and models will be used "],"metadata":{"id":"T_m2cHu-wHCN"}},{"cell_type":"markdown","source":["# Trial 3\n"," \n","reason for change?\n","\n","Testing the methods for hyper parameter tuning is a crucial aspect of the processes and thus must be conducted. In this trial bayesian search will be used.Bayesian optimization utilizes the results from the previous step to decide which hyper parameter combination to evaluate next. The major difference between Bayesian optimization and grid  search is that grid search considers each hyper parameter combination independently, while Bayesian optimization is dependent on the previous evaluation results.\n","\n","\n","expected outcome?\n","\n","The bayesian search should produce similar i results as the grid search used in previous trials, although in less computation time. Bayesian search, searches a distribution rather than a set of parameters, thus the search will for example search max depth's within the range of 10 - 20, where as in grid search only 10 and 20 were searched. \n","\n","\n"],"metadata":{"id":"7INTCDTq0Xz9"}},{"cell_type":"code","source":["\n","np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', SimpleImputer(strategy='median')), #resort back to simple imputation\n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing'))\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","# need to use imblearn pipeline, since SMOTE doesn’t have a ‘fit_transform’ method\n","# thus cannot use it with ‘Scikit-Learn’ pipeline.\n","\n","full_pipline = imbpipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('smote',SMOTE(random_state=11)),\n","        ('my_classifier', XGBClassifier(\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","stratisfied_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\n","                                       \n","param_grid = {\n","    'preprocessor__num__imputer__strategy': Categorical(['mean']),\n","    'my_classifier__n_estimators': Integer(10,100),\n","    'my_classifier__max_depth': Integer(10,20) #,prior='log-uniform')\n","}\n","\n","\n","# but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n","# With Bayes search a fixed number of parameters are sampled from a specified distribution.\n","# n_iter is the parameter set to the number of parameter settings tried. \n","# in previous trials 30 fits were used so i will use n_iter to 6. \n","\n","bayes_search = BayesSearchCV(\n","    full_pipline, param_grid, cv=stratisfied_kfold, verbose=3, n_jobs=1,n_iter=10, \n","    scoring='roc_auc',return_train_score=True)\n","\n","bayes_search.fit(x, y)\n","\n","print('best score {}'.format(bayes_search.best_score_))\n","print('best score {}'.format(bayes_search.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Km3CejEj2Wu4","executionInfo":{"status":"ok","timestamp":1666184844345,"user_tz":240,"elapsed":990665,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"14770510-471f-45b6-a059-d40386b045bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=31, my_classifier__n_estimators=71, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  21.7s\n","[CV 2/5] END my_classifier__max_depth=31, my_classifier__n_estimators=71, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=  21.1s\n","[CV 3/5] END my_classifier__max_depth=31, my_classifier__n_estimators=71, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.887) total time=  20.8s\n","[CV 4/5] END my_classifier__max_depth=31, my_classifier__n_estimators=71, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.870) total time=  21.3s\n","[CV 5/5] END my_classifier__max_depth=31, my_classifier__n_estimators=71, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  20.8s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=20, my_classifier__n_estimators=98, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.880) total time=  24.7s\n","[CV 2/5] END my_classifier__max_depth=20, my_classifier__n_estimators=98, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  24.3s\n","[CV 3/5] END my_classifier__max_depth=20, my_classifier__n_estimators=98, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.887) total time=  24.7s\n","[CV 4/5] END my_classifier__max_depth=20, my_classifier__n_estimators=98, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  24.9s\n","[CV 5/5] END my_classifier__max_depth=20, my_classifier__n_estimators=98, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  24.7s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=31, my_classifier__n_estimators=15, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.832) total time=   7.6s\n","[CV 2/5] END my_classifier__max_depth=31, my_classifier__n_estimators=15, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.836) total time=   7.7s\n","[CV 3/5] END my_classifier__max_depth=31, my_classifier__n_estimators=15, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.860) total time=   7.4s\n","[CV 4/5] END my_classifier__max_depth=31, my_classifier__n_estimators=15, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.837) total time=   7.6s\n","[CV 5/5] END my_classifier__max_depth=31, my_classifier__n_estimators=15, preprocessor__num__imputer__strategy=mean;, score=(train=0.999, test=0.834) total time=   7.2s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=16, my_classifier__n_estimators=80, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.877) total time=  22.2s\n","[CV 2/5] END my_classifier__max_depth=16, my_classifier__n_estimators=80, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  19.9s\n","[CV 3/5] END my_classifier__max_depth=16, my_classifier__n_estimators=80, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.882) total time=  19.8s\n","[CV 4/5] END my_classifier__max_depth=16, my_classifier__n_estimators=80, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  20.2s\n","[CV 5/5] END my_classifier__max_depth=16, my_classifier__n_estimators=80, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  20.0s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=19, my_classifier__n_estimators=32, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.858) total time=  10.4s\n","[CV 2/5] END my_classifier__max_depth=19, my_classifier__n_estimators=32, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.851) total time=  10.3s\n","[CV 3/5] END my_classifier__max_depth=19, my_classifier__n_estimators=32, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  10.2s\n","[CV 4/5] END my_classifier__max_depth=19, my_classifier__n_estimators=32, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.860) total time=  10.3s\n","[CV 5/5] END my_classifier__max_depth=19, my_classifier__n_estimators=32, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.855) total time=  10.4s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=44, my_classifier__n_estimators=99, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  27.1s\n","[CV 2/5] END my_classifier__max_depth=44, my_classifier__n_estimators=99, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=  27.4s\n","[CV 3/5] END my_classifier__max_depth=44, my_classifier__n_estimators=99, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.888) total time=  27.0s\n","[CV 4/5] END my_classifier__max_depth=44, my_classifier__n_estimators=99, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  27.5s\n","[CV 5/5] END my_classifier__max_depth=44, my_classifier__n_estimators=99, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  26.8s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=49, my_classifier__n_estimators=78, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  23.1s\n","[CV 2/5] END my_classifier__max_depth=49, my_classifier__n_estimators=78, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  25.8s\n","[CV 3/5] END my_classifier__max_depth=49, my_classifier__n_estimators=78, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.886) total time=  23.3s\n","[CV 4/5] END my_classifier__max_depth=49, my_classifier__n_estimators=78, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  23.8s\n","[CV 5/5] END my_classifier__max_depth=49, my_classifier__n_estimators=78, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  23.0s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=30, my_classifier__n_estimators=57, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  18.2s\n","[CV 2/5] END my_classifier__max_depth=30, my_classifier__n_estimators=57, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.863) total time=  18.0s\n","[CV 3/5] END my_classifier__max_depth=30, my_classifier__n_estimators=57, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.888) total time=  17.7s\n","[CV 4/5] END my_classifier__max_depth=30, my_classifier__n_estimators=57, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  18.2s\n","[CV 5/5] END my_classifier__max_depth=30, my_classifier__n_estimators=57, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.866) total time=  17.7s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.878) total time=  20.9s\n","[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.874) total time=  20.6s\n","[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.885) total time=  20.6s\n","[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.874) total time=  20.9s\n","[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  20.9s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=25, my_classifier__n_estimators=50, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  16.0s\n","[CV 2/5] END my_classifier__max_depth=25, my_classifier__n_estimators=50, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.861) total time=  17.2s\n","[CV 3/5] END my_classifier__max_depth=25, my_classifier__n_estimators=50, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.881) total time=  16.1s\n","[CV 4/5] END my_classifier__max_depth=25, my_classifier__n_estimators=50, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.867) total time=  16.0s\n","[CV 5/5] END my_classifier__max_depth=25, my_classifier__n_estimators=50, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.864) total time=  16.0s\n","best score 0.8763575240764953\n","best score OrderedDict([('my_classifier__max_depth', 14), ('my_classifier__n_estimators', 91), ('preprocessor__num__imputer__strategy', 'mean')])\n"]}]},{"cell_type":"markdown","source":["###thoughts and observations for trial 3\n","\n","- trial 2: best score 0.8795950960492078 \n","{'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 100, 'preprocessor__num__imputer__strategy': 'mean'}\n","- trial 3: best score 0.8763575240764953\n","('my_classifier__max_depth', 14), ('my_classifier__n_estimators', 91), ('preprocessor__num__imputer__strategy', 'mean')]\n","\n","This trial went as expected, using the same model and preprocessing configurations as trial 2 the bayesian search found similar optimal model parameters although produced slight but insignificantly worse performance. In future trials a larger range of hyper parameters will be tested to see if more optimal configurations are possible. \n","\n","###plan for trial 4\n","\n","The next trial will test the effect of random search on the performance of the model and associated computation time. Again the XGBClassifier with SMOTE and simple imputation will be used to keep consistent and best see the difference in search algorithms."],"metadata":{"id":"w8Oc4C6o4eqo"}},{"cell_type":"markdown","source":["# Trial 4\n"," \n","reason for change?\n","\n","In this trial random search will be used, it is the last of the 3 search algorithms to be tested. This will complete the comparison of the 3 search algorithms and thus is the reason for the change. Random searches pick a fixed number of hyper parameter combinations randomly, so not every single combination is evaluated.The downside is that sometimes the random selection may not include top performance hyper parameter combinations.\n","\n","expected outcome?\n","\n","The optimal set of hyper parameters may not be found, so the performance of the model may not be up to the standards of the previous trials."],"metadata":{"id":"qhKfSgYm55tu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HXgcIq9NlB_","executionInfo":{"status":"ok","timestamp":1666188855266,"user_tz":240,"elapsed":934809,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"04e066f2-0dbc-4dc2-e279-b984ae0231c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 10 candidates, totalling 50 fits\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=77, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.879) total time=  14.0s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=77, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.880) total time=  13.6s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=77, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.887) total time=  13.5s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=77, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.874) total time=  13.5s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=77, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  13.6s\n","[CV 1/5] END my_classifier__max_depth=49, my_classifier__n_estimators=19, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.840) total time=   9.5s\n","[CV 2/5] END my_classifier__max_depth=49, my_classifier__n_estimators=19, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.840) total time=   9.7s\n","[CV 3/5] END my_classifier__max_depth=49, my_classifier__n_estimators=19, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=   9.7s\n","[CV 4/5] END my_classifier__max_depth=49, my_classifier__n_estimators=19, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.846) total time=   9.8s\n","[CV 5/5] END my_classifier__max_depth=49, my_classifier__n_estimators=19, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.847) total time=   9.3s\n","[CV 1/5] END my_classifier__max_depth=46, my_classifier__n_estimators=97, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  27.1s\n","[CV 2/5] END my_classifier__max_depth=46, my_classifier__n_estimators=97, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=  27.9s\n","[CV 3/5] END my_classifier__max_depth=46, my_classifier__n_estimators=97, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.887) total time=  28.8s\n","[CV 4/5] END my_classifier__max_depth=46, my_classifier__n_estimators=97, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  28.1s\n","[CV 5/5] END my_classifier__max_depth=46, my_classifier__n_estimators=97, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  26.7s\n","[CV 1/5] END my_classifier__max_depth=34, my_classifier__n_estimators=22, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.846) total time=  10.2s\n","[CV 2/5] END my_classifier__max_depth=34, my_classifier__n_estimators=22, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.842) total time=  10.5s\n","[CV 3/5] END my_classifier__max_depth=34, my_classifier__n_estimators=22, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.875) total time=  10.2s\n","[CV 4/5] END my_classifier__max_depth=34, my_classifier__n_estimators=22, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.855) total time=  10.1s\n","[CV 5/5] END my_classifier__max_depth=34, my_classifier__n_estimators=22, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.847) total time=   9.8s\n","[CV 1/5] END my_classifier__max_depth=48, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  17.5s\n","[CV 2/5] END my_classifier__max_depth=48, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.861) total time=  18.2s\n","[CV 3/5] END my_classifier__max_depth=48, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.886) total time=  17.6s\n","[CV 4/5] END my_classifier__max_depth=48, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.865) total time=  17.7s\n","[CV 5/5] END my_classifier__max_depth=48, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.867) total time=  16.7s\n","[CV 1/5] END my_classifier__max_depth=34, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.880) total time=  25.3s\n","[CV 2/5] END my_classifier__max_depth=34, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=  26.8s\n","[CV 3/5] END my_classifier__max_depth=34, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.889) total time=  25.5s\n","[CV 4/5] END my_classifier__max_depth=34, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.877) total time=  25.5s\n","[CV 5/5] END my_classifier__max_depth=34, my_classifier__n_estimators=91, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  27.5s\n","[CV 1/5] END my_classifier__max_depth=23, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.878) total time=  22.2s\n","[CV 2/5] END my_classifier__max_depth=23, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.870) total time=  21.9s\n","[CV 3/5] END my_classifier__max_depth=23, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.886) total time=  21.8s\n","[CV 4/5] END my_classifier__max_depth=23, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  22.6s\n","[CV 5/5] END my_classifier__max_depth=23, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  22.4s\n","[CV 1/5] END my_classifier__max_depth=26, my_classifier__n_estimators=79, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time=  22.2s\n","[CV 2/5] END my_classifier__max_depth=26, my_classifier__n_estimators=79, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.865) total time=  22.0s\n","[CV 3/5] END my_classifier__max_depth=26, my_classifier__n_estimators=79, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.886) total time=  21.7s\n","[CV 4/5] END my_classifier__max_depth=26, my_classifier__n_estimators=79, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.870) total time=  22.7s\n","[CV 5/5] END my_classifier__max_depth=26, my_classifier__n_estimators=79, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  25.4s\n","[CV 1/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.879) total time=  17.8s\n","[CV 2/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.880) total time=  16.0s\n","[CV 3/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.887) total time=  15.9s\n","[CV 4/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  17.1s\n","[CV 5/5] END my_classifier__max_depth=10, my_classifier__n_estimators=92, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.877) total time=  17.5s\n","[CV 1/5] END my_classifier__max_depth=39, my_classifier__n_estimators=29, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.857) total time=  14.6s\n","[CV 2/5] END my_classifier__max_depth=39, my_classifier__n_estimators=29, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.850) total time=  13.2s\n","[CV 3/5] END my_classifier__max_depth=39, my_classifier__n_estimators=29, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.881) total time=  12.3s\n","[CV 4/5] END my_classifier__max_depth=39, my_classifier__n_estimators=29, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.863) total time=  12.3s\n","[CV 5/5] END my_classifier__max_depth=39, my_classifier__n_estimators=29, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.855) total time=  11.9s\n","best score 0.8793704635149415\n","best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 92, 'preprocessor__num__imputer__strategy': 'mean'}\n"]}],"source":["np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', SimpleImputer(strategy='median')),\n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing'))\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","# need to use imblearn pipeline, since SMOTE doesn’t have a ‘fit_transform’ method\n","# thus cannot use it with ‘Scikit-Learn’ pipeline.\n","\n","full_pipline = imbpipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('smote',SMOTE(random_state=11)),\n","        ('my_classifier', XGBClassifier(\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","stratisfied_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\n","                                       \n","param_grid = {\n","    'preprocessor__num__imputer__strategy': Categorical(['mean']),\n","    'my_classifier__n_estimators': sp_randInt(10,100),\n","    'my_classifier__max_depth': sp_randInt(10,50)\n","}\n","\n","rand_search = RandomizedSearchCV(\n","    full_pipline, param_grid, cv=stratisfied_kfold, verbose=3, n_jobs=1, \n","    scoring='roc_auc',return_train_score=True)\n","\n","rand_search.fit(x, y)\n","\n","print('best score {}'.format(rand_search.best_score_))\n","print('best score {}'.format(rand_search.best_params_))"]},{"cell_type":"markdown","source":["###thoughts and observations for trial 4\n","\n","- trial 2: best score 0.8795950960492078 \n","{'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 100, 'preprocessor__num__imputer__strategy': 'mean'}\n","- trial 4: best score 0.8793704635149415\n","{'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 92, 'preprocessor__num__imputer__strategy': 'mean'}\n","\n","The trial went as expected, the random search searched over the 50 different fits and was Abel to find a very similar set of parameters seen in trial 2. If more fits were tested the optimal parameters set found in trail 2 may have been found. \n","\n","\n","###plan for trial 5\n","\n","For trail 5 I will explore the possibility of finding a more optimal model by searching a wider range of  hyper parameter values using the bayesian search method.\n"],"metadata":{"id":"90jWG_TEmm1y"}},{"cell_type":"markdown","source":["# Trial 5\n"," \n","reason for change?\n","\n","As seen in trail 3, bayesian search was not able to find a more optimal hyper parameter set with slightly worse performing model. To determine if an even more optimal model can be found the range of the hyper parameter values within the parameter grid will be increased. In addition we will revise the use of KNN imputation and include the number of neighbours in the search to determine if this can yield better performance. \n","\n","expected outcome?\n","\n","With increasing the distribution over which the bayesian search will explore the possibility of a more optimal model increases. Hopefully a more optimal better performing model will be found. The added interactions over the number of neighbours used in the KNN imputation will increase compute time although may results in better performance. "],"metadata":{"id":"xKt-cHpnZOgI"}},{"cell_type":"code","source":["\n","np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', KNNImputer(n_neighbors=2)),\n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing'))\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","# need to use imblearn pipeline, since SMOTE doesn’t have a ‘fit_transform’ method\n","# thus cannot use it with ‘Scikit-Learn’ pipeline.\n","\n","full_pipline = imbpipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('smote',SMOTE(random_state=11)),\n","        ('my_classifier', XGBClassifier(\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","stratisfied_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\n","                                       \n","param_grid = {\n","    'preprocessor__num__imputer__n_neighbors': Integer(2,10),\n","    'my_classifier__n_estimators': Integer(5,200),\n","    'my_classifier__max_depth': Integer(5,100)\n","}\n","\n","# With Bayes search a fixed number of parameters are sampled from a specified distribution.\n","# n_iter is the parameter set to the number of parameter settings tried. \n","# in previous trials 30 fits were used so i will use n_iter to 6. \n","\n","bayes_search_final = BayesSearchCV(\n","    full_pipline, param_grid, cv=stratisfied_kfold, verbose=3, n_jobs=1,n_iter=15, \n","    scoring='roc_auc',return_train_score=True)\n","\n","bayes_search_final.fit(x, y)\n","\n","print('best score {}'.format(bayes_search_final.best_score_))\n","print('best score {}'.format(bayes_search_final.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IP9SHkYkcrxG","executionInfo":{"status":"ok","timestamp":1666377437820,"user_tz":240,"elapsed":5636189,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"75981ffe-3ccf-4685-8e8e-3d176f0a6148"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=55, my_classifier__n_estimators=137, preprocessor__num__imputer__n_neighbors=7;, score=(train=1.000, test=0.861) total time=  54.2s\n","[CV 2/5] END my_classifier__max_depth=55, my_classifier__n_estimators=137, preprocessor__num__imputer__n_neighbors=7;, score=(train=1.000, test=0.869) total time=  55.2s\n","[CV 3/5] END my_classifier__max_depth=55, my_classifier__n_estimators=137, preprocessor__num__imputer__n_neighbors=7;, score=(train=1.000, test=0.879) total time=  56.4s\n","[CV 4/5] END my_classifier__max_depth=55, my_classifier__n_estimators=137, preprocessor__num__imputer__n_neighbors=7;, score=(train=1.000, test=0.865) total time=  58.3s\n","[CV 5/5] END my_classifier__max_depth=55, my_classifier__n_estimators=137, preprocessor__num__imputer__n_neighbors=7;, score=(train=1.000, test=0.857) total time=  55.3s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=30, my_classifier__n_estimators=196, preprocessor__num__imputer__n_neighbors=9;, score=(train=1.000, test=0.869) total time= 1.1min\n","[CV 2/5] END my_classifier__max_depth=30, my_classifier__n_estimators=196, preprocessor__num__imputer__n_neighbors=9;, score=(train=1.000, test=0.864) total time= 1.1min\n","[CV 3/5] END my_classifier__max_depth=30, my_classifier__n_estimators=196, preprocessor__num__imputer__n_neighbors=9;, score=(train=1.000, test=0.880) total time= 1.1min\n","[CV 4/5] END my_classifier__max_depth=30, my_classifier__n_estimators=196, preprocessor__num__imputer__n_neighbors=9;, score=(train=1.000, test=0.867) total time= 1.1min\n","[CV 5/5] END my_classifier__max_depth=30, my_classifier__n_estimators=196, preprocessor__num__imputer__n_neighbors=9;, score=(train=1.000, test=0.864) total time= 1.1min\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=55, my_classifier__n_estimators=16, preprocessor__num__imputer__n_neighbors=5;, score=(train=0.999, test=0.815) total time=  34.8s\n","[CV 2/5] END my_classifier__max_depth=55, my_classifier__n_estimators=16, preprocessor__num__imputer__n_neighbors=5;, score=(train=0.999, test=0.830) total time=  34.3s\n","[CV 3/5] END my_classifier__max_depth=55, my_classifier__n_estimators=16, preprocessor__num__imputer__n_neighbors=5;, score=(train=1.000, test=0.843) total time=  35.5s\n","[CV 4/5] END my_classifier__max_depth=55, my_classifier__n_estimators=16, preprocessor__num__imputer__n_neighbors=5;, score=(train=0.999, test=0.826) total time=  35.9s\n","[CV 5/5] END my_classifier__max_depth=55, my_classifier__n_estimators=16, preprocessor__num__imputer__n_neighbors=5;, score=(train=0.999, test=0.836) total time=  33.1s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=19, my_classifier__n_estimators=158, preprocessor__num__imputer__n_neighbors=6;, score=(train=1.000, test=0.861) total time=  59.2s\n","[CV 2/5] END my_classifier__max_depth=19, my_classifier__n_estimators=158, preprocessor__num__imputer__n_neighbors=6;, score=(train=1.000, test=0.863) total time=  57.9s\n","[CV 3/5] END my_classifier__max_depth=19, my_classifier__n_estimators=158, preprocessor__num__imputer__n_neighbors=6;, score=(train=1.000, test=0.883) total time=  56.9s\n","[CV 4/5] END my_classifier__max_depth=19, my_classifier__n_estimators=158, preprocessor__num__imputer__n_neighbors=6;, score=(train=1.000, test=0.866) total time=  56.8s\n","[CV 5/5] END my_classifier__max_depth=19, my_classifier__n_estimators=158, preprocessor__num__imputer__n_neighbors=6;, score=(train=1.000, test=0.864) total time=  56.7s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=27, my_classifier__n_estimators=52, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.858) total time=  42.9s\n","[CV 2/5] END my_classifier__max_depth=27, my_classifier__n_estimators=52, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.856) total time=  42.7s\n","[CV 3/5] END my_classifier__max_depth=27, my_classifier__n_estimators=52, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.874) total time=  44.3s\n","[CV 4/5] END my_classifier__max_depth=27, my_classifier__n_estimators=52, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.861) total time=  42.7s\n","[CV 5/5] END my_classifier__max_depth=27, my_classifier__n_estimators=52, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.856) total time=  39.8s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=85, my_classifier__n_estimators=198, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.863) total time= 1.1min\n","[CV 2/5] END my_classifier__max_depth=85, my_classifier__n_estimators=198, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.865) total time= 1.1min\n","[CV 3/5] END my_classifier__max_depth=85, my_classifier__n_estimators=198, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.879) total time= 1.1min\n","[CV 4/5] END my_classifier__max_depth=85, my_classifier__n_estimators=198, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.869) total time= 1.1min\n","[CV 5/5] END my_classifier__max_depth=85, my_classifier__n_estimators=198, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.865) total time= 1.0min\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=97, my_classifier__n_estimators=153, preprocessor__num__imputer__n_neighbors=5;, score=(train=1.000, test=0.863) total time=  58.8s\n","[CV 2/5] END my_classifier__max_depth=97, my_classifier__n_estimators=153, preprocessor__num__imputer__n_neighbors=5;, score=(train=1.000, test=0.863) total time=  58.2s\n","[CV 3/5] END my_classifier__max_depth=97, my_classifier__n_estimators=153, preprocessor__num__imputer__n_neighbors=5;, score=(train=1.000, test=0.876) total time=  59.1s\n","[CV 4/5] END my_classifier__max_depth=97, my_classifier__n_estimators=153, preprocessor__num__imputer__n_neighbors=5;, score=(train=1.000, test=0.866) total time= 1.0min\n","[CV 5/5] END my_classifier__max_depth=97, my_classifier__n_estimators=153, preprocessor__num__imputer__n_neighbors=5;, score=(train=1.000, test=0.866) total time=  56.2s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=53, my_classifier__n_estimators=108, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.863) total time=  53.1s\n","[CV 2/5] END my_classifier__max_depth=53, my_classifier__n_estimators=108, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.863) total time=  53.4s\n","[CV 3/5] END my_classifier__max_depth=53, my_classifier__n_estimators=108, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.877) total time=  55.7s\n","[CV 4/5] END my_classifier__max_depth=53, my_classifier__n_estimators=108, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.868) total time=  53.1s\n","[CV 5/5] END my_classifier__max_depth=53, my_classifier__n_estimators=108, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.861) total time=  52.0s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=14, my_classifier__n_estimators=180, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.866) total time=  60.0s\n","[CV 2/5] END my_classifier__max_depth=14, my_classifier__n_estimators=180, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.871) total time=  58.5s\n","[CV 3/5] END my_classifier__max_depth=14, my_classifier__n_estimators=180, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.884) total time= 1.0min\n","[CV 4/5] END my_classifier__max_depth=14, my_classifier__n_estimators=180, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.873) total time=  59.3s\n","[CV 5/5] END my_classifier__max_depth=14, my_classifier__n_estimators=180, preprocessor__num__imputer__n_neighbors=8;, score=(train=1.000, test=0.863) total time=  57.9s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=40, my_classifier__n_estimators=91, preprocessor__num__imputer__n_neighbors=4;, score=(train=1.000, test=0.863) total time=  50.7s\n","[CV 2/5] END my_classifier__max_depth=40, my_classifier__n_estimators=91, preprocessor__num__imputer__n_neighbors=4;, score=(train=1.000, test=0.861) total time=  49.8s\n","[CV 3/5] END my_classifier__max_depth=40, my_classifier__n_estimators=91, preprocessor__num__imputer__n_neighbors=4;, score=(train=1.000, test=0.875) total time=  49.5s\n","[CV 4/5] END my_classifier__max_depth=40, my_classifier__n_estimators=91, preprocessor__num__imputer__n_neighbors=4;, score=(train=1.000, test=0.864) total time=  50.9s\n","[CV 5/5] END my_classifier__max_depth=40, my_classifier__n_estimators=91, preprocessor__num__imputer__n_neighbors=4;, score=(train=1.000, test=0.863) total time=  45.4s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=88, my_classifier__n_estimators=71, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.863) total time=  47.2s\n","[CV 2/5] END my_classifier__max_depth=88, my_classifier__n_estimators=71, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.861) total time=  46.8s\n","[CV 3/5] END my_classifier__max_depth=88, my_classifier__n_estimators=71, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.875) total time=  47.7s\n","[CV 4/5] END my_classifier__max_depth=88, my_classifier__n_estimators=71, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.869) total time=  48.8s\n","[CV 5/5] END my_classifier__max_depth=88, my_classifier__n_estimators=71, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.852) total time=  44.1s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=99, my_classifier__n_estimators=124, preprocessor__num__imputer__n_neighbors=2;, score=(train=1.000, test=0.857) total time=  51.1s\n","[CV 2/5] END my_classifier__max_depth=99, my_classifier__n_estimators=124, preprocessor__num__imputer__n_neighbors=2;, score=(train=1.000, test=0.865) total time=  48.5s\n","[CV 3/5] END my_classifier__max_depth=99, my_classifier__n_estimators=124, preprocessor__num__imputer__n_neighbors=2;, score=(train=1.000, test=0.879) total time=  48.6s\n","[CV 4/5] END my_classifier__max_depth=99, my_classifier__n_estimators=124, preprocessor__num__imputer__n_neighbors=2;, score=(train=1.000, test=0.864) total time=  50.0s\n","[CV 5/5] END my_classifier__max_depth=99, my_classifier__n_estimators=124, preprocessor__num__imputer__n_neighbors=2;, score=(train=1.000, test=0.863) total time=  46.7s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=98, my_classifier__n_estimators=36, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.852) total time=  41.1s\n","[CV 2/5] END my_classifier__max_depth=98, my_classifier__n_estimators=36, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.850) total time=  39.5s\n","[CV 3/5] END my_classifier__max_depth=98, my_classifier__n_estimators=36, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.866) total time=  40.3s\n","[CV 4/5] END my_classifier__max_depth=98, my_classifier__n_estimators=36, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.855) total time=  39.4s\n","[CV 5/5] END my_classifier__max_depth=98, my_classifier__n_estimators=36, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.842) total time=  35.7s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=5, my_classifier__n_estimators=182, preprocessor__num__imputer__n_neighbors=2;, score=(train=0.997, test=0.869) total time=  35.2s\n","[CV 2/5] END my_classifier__max_depth=5, my_classifier__n_estimators=182, preprocessor__num__imputer__n_neighbors=2;, score=(train=0.996, test=0.872) total time=  35.7s\n","[CV 3/5] END my_classifier__max_depth=5, my_classifier__n_estimators=182, preprocessor__num__imputer__n_neighbors=2;, score=(train=0.995, test=0.885) total time=  36.1s\n","[CV 4/5] END my_classifier__max_depth=5, my_classifier__n_estimators=182, preprocessor__num__imputer__n_neighbors=2;, score=(train=0.996, test=0.860) total time=  34.8s\n","[CV 5/5] END my_classifier__max_depth=5, my_classifier__n_estimators=182, preprocessor__num__imputer__n_neighbors=2;, score=(train=0.996, test=0.865) total time=  33.9s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__max_depth=100, my_classifier__n_estimators=181, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.868) total time= 1.1min\n","[CV 2/5] END my_classifier__max_depth=100, my_classifier__n_estimators=181, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.865) total time= 1.0min\n","[CV 3/5] END my_classifier__max_depth=100, my_classifier__n_estimators=181, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.882) total time= 1.0min\n","[CV 4/5] END my_classifier__max_depth=100, my_classifier__n_estimators=181, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.871) total time= 1.0min\n","[CV 5/5] END my_classifier__max_depth=100, my_classifier__n_estimators=181, preprocessor__num__imputer__n_neighbors=10;, score=(train=1.000, test=0.860) total time=  59.4s\n","best score 0.8712110197941778\n","best score OrderedDict([('my_classifier__max_depth', 14), ('my_classifier__n_estimators', 180), ('preprocessor__num__imputer__n_neighbors', 8)])\n"]}]},{"cell_type":"markdown","source":["###thoughts and observations for trial 5\n","\n","- trial 3: best score 0.8806050740846902\n","('my_classifier__max_depth', 11), ('my_classifier__n_estimators', 100), ('preprocessor__num__imputer__strategy', 'mean')\n","- trial 5: best score 0.8804237989062245\n","('my_classifier__max_depth', 10), ('my_classifier__n_estimators', 200), ('preprocessor__num__imputer__strategy', 'mean')])\n","\n","The increased distribution of which the bayesian search explored did not result in a more optimal set of hyper-parameters. This was a possible outcome in which we can now move forward and test alternative classificaiton models. \n","\n","###plan for trial 6\n","\n","For trail 6 i will explore alternative classifiers, specifically AdaBoost. I will use the same configutions for the pipline such as using SMOTE, simple imputaiton, and bayesian search as these have generated the best results so far. "],"metadata":{"id":"6EDmaOuBeYk8"}},{"cell_type":"markdown","source":["# Trial 6\n"," \n","reason for change?\n","\n","XGBoost or XGBClassifier is a boosting method, other classifiers such as random forests are bagging methods. Boosting methods work better on imbalanced datasets such as the one we have in this challenge. Boosting methods put more importance on misclassified observations, so intuitively with an imbalanced dataset when the model first fails to detect the anomaly it will give more weightage to this imbalance in upcoming iterations. Thus increasing the models ability to predict the class with low representation.\n","\n","expected outcome?\n","\n","Adaboost is more prone to overfitting than XGBoost, although in some cases can perform better than XGBoost. The results may be a better performing model although there is no way to tell until the trial is complete. "],"metadata":{"id":"8bjLeBU3f8ax"}},{"cell_type":"code","source":["\n","np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', SimpleImputer(strategy='median')),\n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing'))\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","# need to use imblearn pipeline, since SMOTE doesn’t have a ‘fit_transform’ method\n","# thus cannot use it with ‘Scikit-Learn’ pipeline.\n","\n","dtc = DecisionTreeClassifier()\n","\n","full_pipline = imbpipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('smote',SMOTE(random_state=11)),\n","        ('my_classifier', AdaBoostClassifier(base_estimator = dtc))\n","    ]\n",")\n","\n","stratisfied_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\n","                                       \n","param_grid = {\n","    'preprocessor__num__imputer__strategy': Categorical(['mean']),\n","    'my_classifier__n_estimators':  Integer(10,100),\n","    'my_classifier__learning_rate':  Real(0.001, 1, prior='log-uniform'),\n","    'my_classifier__base_estimator__criterion': Categorical(['gini', 'entropy']),\n","    'my_classifier__base_estimator__max_depth': Integer(1,15)\n","}\n","\n","bayes_search = BayesSearchCV(\n","    full_pipline, param_grid, cv=stratisfied_kfold, verbose=3, n_jobs=1,n_iter=15, \n","    scoring='roc_auc',return_train_score=True)\n","\n","bayes_search.fit(x, y)\n","\n","print('best score {}'.format(bayes_search.best_score_))\n","print('best score {}'.format(bayes_search.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7prOYYjALfU","executionInfo":{"status":"ok","timestamp":1666291648742,"user_tz":240,"elapsed":2988183,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"3b37d1c0-bdbd-4c8b-feb9-cf4600b1fc98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=10, my_classifier__learning_rate=0.07381238832487748, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.739) total time= 1.1min\n","[CV 2/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=10, my_classifier__learning_rate=0.07381238832487748, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.712) total time= 1.2min\n","[CV 3/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=10, my_classifier__learning_rate=0.07381238832487748, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.759) total time= 1.2min\n","[CV 4/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=10, my_classifier__learning_rate=0.07381238832487748, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.778) total time= 1.1min\n","[CV 5/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=10, my_classifier__learning_rate=0.07381238832487748, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.731) total time= 1.2min\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=13, my_classifier__learning_rate=0.11926469143720957, my_classifier__n_estimators=43, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.829) total time= 1.3min\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=13, my_classifier__learning_rate=0.11926469143720957, my_classifier__n_estimators=43, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.827) total time= 1.2min\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=13, my_classifier__learning_rate=0.11926469143720957, my_classifier__n_estimators=43, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.864) total time= 1.2min\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=13, my_classifier__learning_rate=0.11926469143720957, my_classifier__n_estimators=43, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.823) total time= 1.4min\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=13, my_classifier__learning_rate=0.11926469143720957, my_classifier__n_estimators=43, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.826) total time= 1.3min\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=8, my_classifier__learning_rate=0.0015906928144020962, my_classifier__n_estimators=16, preprocessor__num__imputer__strategy=mean;, score=(train=0.923, test=0.732) total time=  13.3s\n","[CV 2/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=8, my_classifier__learning_rate=0.0015906928144020962, my_classifier__n_estimators=16, preprocessor__num__imputer__strategy=mean;, score=(train=0.944, test=0.724) total time=  15.1s\n","[CV 3/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=8, my_classifier__learning_rate=0.0015906928144020962, my_classifier__n_estimators=16, preprocessor__num__imputer__strategy=mean;, score=(train=0.925, test=0.789) total time=  13.5s\n","[CV 4/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=8, my_classifier__learning_rate=0.0015906928144020962, my_classifier__n_estimators=16, preprocessor__num__imputer__strategy=mean;, score=(train=0.900, test=0.765) total time=  12.3s\n","[CV 5/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=8, my_classifier__learning_rate=0.0015906928144020962, my_classifier__n_estimators=16, preprocessor__num__imputer__strategy=mean;, score=(train=0.900, test=0.743) total time=  12.9s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=6, my_classifier__learning_rate=0.00215303934892735, my_classifier__n_estimators=56, preprocessor__num__imputer__strategy=mean;, score=(train=0.919, test=0.832) total time=  39.5s\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=6, my_classifier__learning_rate=0.00215303934892735, my_classifier__n_estimators=56, preprocessor__num__imputer__strategy=mean;, score=(train=0.924, test=0.809) total time=  39.7s\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=6, my_classifier__learning_rate=0.00215303934892735, my_classifier__n_estimators=56, preprocessor__num__imputer__strategy=mean;, score=(train=0.921, test=0.851) total time=  41.0s\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=6, my_classifier__learning_rate=0.00215303934892735, my_classifier__n_estimators=56, preprocessor__num__imputer__strategy=mean;, score=(train=0.918, test=0.833) total time=  39.7s\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=6, my_classifier__learning_rate=0.00215303934892735, my_classifier__n_estimators=56, preprocessor__num__imputer__strategy=mean;, score=(train=0.914, test=0.815) total time=  39.4s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=4, my_classifier__learning_rate=0.0013563693364318566, my_classifier__n_estimators=65, preprocessor__num__imputer__strategy=mean;, score=(train=0.833, test=0.811) total time=  26.4s\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=4, my_classifier__learning_rate=0.0013563693364318566, my_classifier__n_estimators=65, preprocessor__num__imputer__strategy=mean;, score=(train=0.847, test=0.813) total time=  26.2s\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=4, my_classifier__learning_rate=0.0013563693364318566, my_classifier__n_estimators=65, preprocessor__num__imputer__strategy=mean;, score=(train=0.842, test=0.836) total time=  26.7s\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=4, my_classifier__learning_rate=0.0013563693364318566, my_classifier__n_estimators=65, preprocessor__num__imputer__strategy=mean;, score=(train=0.845, test=0.829) total time=  26.1s\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=4, my_classifier__learning_rate=0.0013563693364318566, my_classifier__n_estimators=65, preprocessor__num__imputer__strategy=mean;, score=(train=0.843, test=0.822) total time=  27.2s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.00800937670706805, my_classifier__n_estimators=28, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.841) total time=  35.9s\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.00800937670706805, my_classifier__n_estimators=28, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.825) total time=  33.2s\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.00800937670706805, my_classifier__n_estimators=28, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.853) total time=  34.6s\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.00800937670706805, my_classifier__n_estimators=28, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.833) total time=  33.9s\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.00800937670706805, my_classifier__n_estimators=28, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.840) total time=  33.8s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=15, my_classifier__learning_rate=0.0022573082500420487, my_classifier__n_estimators=13, preprocessor__num__imputer__strategy=mean;, score=(train=0.991, test=0.559) total time=  21.7s\n","[CV 2/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=15, my_classifier__learning_rate=0.0022573082500420487, my_classifier__n_estimators=13, preprocessor__num__imputer__strategy=mean;, score=(train=0.992, test=0.590) total time=  22.9s\n","[CV 3/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=15, my_classifier__learning_rate=0.0022573082500420487, my_classifier__n_estimators=13, preprocessor__num__imputer__strategy=mean;, score=(train=0.988, test=0.644) total time=  22.9s\n","[CV 4/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=15, my_classifier__learning_rate=0.0022573082500420487, my_classifier__n_estimators=13, preprocessor__num__imputer__strategy=mean;, score=(train=0.981, test=0.626) total time=  20.0s\n","[CV 5/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=15, my_classifier__learning_rate=0.0022573082500420487, my_classifier__n_estimators=13, preprocessor__num__imputer__strategy=mean;, score=(train=0.984, test=0.595) total time=  21.5s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=11, my_classifier__learning_rate=0.16486690158067385, my_classifier__n_estimators=76, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.826) total time= 2.0min\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=11, my_classifier__learning_rate=0.16486690158067385, my_classifier__n_estimators=76, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.825) total time= 2.1min\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=11, my_classifier__learning_rate=0.16486690158067385, my_classifier__n_estimators=76, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.876) total time= 2.0min\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=11, my_classifier__learning_rate=0.16486690158067385, my_classifier__n_estimators=76, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.829) total time= 2.1min\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=11, my_classifier__learning_rate=0.16486690158067385, my_classifier__n_estimators=76, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.813) total time= 2.0min\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=14, my_classifier__learning_rate=0.0021128032983187914, my_classifier__n_estimators=45, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.749) total time= 1.3min\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=14, my_classifier__learning_rate=0.0021128032983187914, my_classifier__n_estimators=45, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.747) total time= 1.3min\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=14, my_classifier__learning_rate=0.0021128032983187914, my_classifier__n_estimators=45, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.804) total time= 1.3min\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=14, my_classifier__learning_rate=0.0021128032983187914, my_classifier__n_estimators=45, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.818) total time= 1.3min\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=14, my_classifier__learning_rate=0.0021128032983187914, my_classifier__n_estimators=45, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.805) total time= 1.3min\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.019130635771293165, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.814) total time=  49.2s\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.019130635771293165, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.795) total time=  47.7s\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.019130635771293165, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.846) total time=  50.6s\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.019130635771293165, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.819) total time=  48.0s\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=0.019130635771293165, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.824) total time=  49.4s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=0.867, test=0.825) total time=   4.6s\n","[CV 2/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=0.873, test=0.841) total time=   4.6s\n","[CV 3/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=0.866, test=0.855) total time=   4.6s\n","[CV 4/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=0.872, test=0.842) total time=   4.6s\n","[CV 5/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=49, preprocessor__num__imputer__strategy=mean;, score=(train=0.870, test=0.839) total time=   4.6s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.828, test=0.804) total time=   1.6s\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.831, test=0.819) total time=   1.6s\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.826, test=0.831) total time=   1.7s\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.831, test=0.811) total time=   1.7s\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=0.825, test=0.825) total time=   1.7s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=0.001, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=0.775, test=0.762) total time=   8.8s\n","[CV 2/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=0.001, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=0.774, test=0.756) total time=   8.7s\n","[CV 3/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=0.001, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=0.768, test=0.779) total time=   8.8s\n","[CV 4/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=0.001, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=0.773, test=0.781) total time=   9.6s\n","[CV 5/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=1, my_classifier__learning_rate=0.001, my_classifier__n_estimators=100, preprocessor__num__imputer__strategy=mean;, score=(train=0.766, test=0.760) total time=   8.7s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.774) total time=  13.3s\n","[CV 2/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.757) total time=  13.9s\n","[CV 3/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.782) total time=  13.5s\n","[CV 4/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.770) total time=  13.5s\n","[CV 5/5] END my_classifier__base_estimator__criterion=entropy, my_classifier__base_estimator__max_depth=9, my_classifier__learning_rate=1.0, my_classifier__n_estimators=10, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.755) total time=  12.3s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=5, my_classifier__learning_rate=1.0, my_classifier__n_estimators=81, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.784) total time=  32.1s\n","[CV 2/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=5, my_classifier__learning_rate=1.0, my_classifier__n_estimators=81, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.779) total time=  31.7s\n","[CV 3/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=5, my_classifier__learning_rate=1.0, my_classifier__n_estimators=81, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.808) total time=  32.4s\n","[CV 4/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=5, my_classifier__learning_rate=1.0, my_classifier__n_estimators=81, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.775) total time=  33.0s\n","[CV 5/5] END my_classifier__base_estimator__criterion=gini, my_classifier__base_estimator__max_depth=5, my_classifier__learning_rate=1.0, my_classifier__n_estimators=81, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.773) total time=  31.9s\n","best score 0.8405708098147681\n","best score OrderedDict([('my_classifier__base_estimator__criterion', 'gini'), ('my_classifier__base_estimator__max_depth', 1), ('my_classifier__learning_rate', 1.0), ('my_classifier__n_estimators', 49), ('preprocessor__num__imputer__strategy', 'mean')])\n"]}]},{"cell_type":"markdown","source":["###thoughts and observations for trial 6\n","\n","- trial 5: best score 0.8804237989062245\n","- trial 6: best score 0.8405708098147681\n","\n","After exploring and researching alternative classifiers, I am satisfied with the final results of the trails. It has been determined the XGBoost is a better model than AdaBoost for this specific challenge and generally. In future experiments more models could be tested although I believe XGBoost will come out on top the majority of the time.\n","\n","###plan for trial 7\n","\n","The last attemt to fixing the overfitting problem will take place in this trail. Increasing the L1 and L2 regularization parameters in the XGBoost model will hopefully help address the over fitting problem, seen in all trails 1-6. \n"],"metadata":{"id":"m5bXL9YyAEZx"}},{"cell_type":"markdown","source":["# Trial 7\n"," \n","reason for change?\n","\n","Alpha and Lambda are the regularization hyper parameters in the XGBoost model. Through trials 1 - 6 techniques such as SMOTE and KNNimputer have been used to try to address the overfitting problem. They have been unsuccessful, in this trial we will go into the model altering the standardization parameters to make the model less complex. \n","\n","expected outcome?\n","\n","With added standardization the training accuracy should drop below 100% which is what we've been seeing in almost all previous trials, this should result in better test accuracies as their will be less overfitting. "],"metadata":{"id":"6gtPOokrXUDa"}},{"cell_type":"code","source":["\n","np.random.seed(0)\n","\n","transformer_numeric = Pipeline(\n","    steps=[\n","        ('imputer', SimpleImputer(strategy='median')), #resort back to simple imputation\n","        ('scaler', StandardScaler())]\n",")\n","\n","transformer_categorical = Pipeline(\n","    steps=[\n","        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n","        ('imputer', SimpleImputer(strategy='most_frequent', fill_value='missing'))\n","    ]\n",")\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', transformer_numeric, features_numeric),\n","        ('cat', transformer_categorical, features_categorical)\n","    ]\n",")\n","\n","# need to use imblearn pipeline, since SMOTE doesn’t have a ‘fit_transform’ method\n","# thus cannot use it with ‘Scikit-Learn’ pipeline.\n","\n","full_pipline = imbpipeline(\n","    steps=[\n","        ('preprocessor', preprocessor),\n","        ('smote',SMOTE(random_state=11)),\n","        ('my_classifier', XGBClassifier(\n","            objective='binary:logistic', seed=1))\n","    ]\n",")\n","\n","stratisfied_kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=11)\n","\n","#alpha and lambda introduced to the parameter grid                                     \n","param_grid = {\n","    'preprocessor__num__imputer__strategy': Categorical(['mean']),\n","    'my_classifier__n_estimators': Integer(10,100),\n","    'my_classifier__max_depth': Integer(10,20), #,prior='log-uniform')\n","    'my_classifier__lambda': Integer(50,200),\n","    'my_classifier__alpha': Integer(50,200)\n","}\n","\n","\n","\n","\n","bayes_search_lambda = BayesSearchCV(\n","    full_pipline, param_grid, cv=stratisfied_kfold, verbose=3, n_jobs=1,n_iter=10, \n","    scoring='roc_auc',return_train_score=True)\n","\n","bayes_search_lambda.fit(x, y)\n","\n","print('best score {}'.format(bayes_search_lambda.best_score_))\n","print('best score {}'.format(bayes_search_lambda.best_params_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tv-K2Bl4-x5T","executionInfo":{"status":"ok","timestamp":1666623304344,"user_tz":240,"elapsed":728766,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"c433a6b5-ae1b-4653-9a93-3770dab2615a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=130, my_classifier__lambda=151, my_classifier__max_depth=16, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.875) total time=  18.1s\n","[CV 2/5] END my_classifier__alpha=130, my_classifier__lambda=151, my_classifier__max_depth=16, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  17.2s\n","[CV 3/5] END my_classifier__alpha=130, my_classifier__lambda=151, my_classifier__max_depth=16, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.881) total time=  16.9s\n","[CV 4/5] END my_classifier__alpha=130, my_classifier__lambda=151, my_classifier__max_depth=16, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  17.6s\n","[CV 5/5] END my_classifier__alpha=130, my_classifier__lambda=151, my_classifier__max_depth=16, my_classifier__n_estimators=68, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  19.8s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=89, my_classifier__lambda=197, my_classifier__max_depth=19, my_classifier__n_estimators=64, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.875) total time=  20.5s\n","[CV 2/5] END my_classifier__alpha=89, my_classifier__lambda=197, my_classifier__max_depth=19, my_classifier__n_estimators=64, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.864) total time=  18.1s\n","[CV 3/5] END my_classifier__alpha=89, my_classifier__lambda=197, my_classifier__max_depth=19, my_classifier__n_estimators=64, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.883) total time=  20.5s\n","[CV 4/5] END my_classifier__alpha=89, my_classifier__lambda=197, my_classifier__max_depth=19, my_classifier__n_estimators=64, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  19.9s\n","[CV 5/5] END my_classifier__alpha=89, my_classifier__lambda=197, my_classifier__max_depth=19, my_classifier__n_estimators=64, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  20.1s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=129, my_classifier__lambda=59, my_classifier__max_depth=13, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.852) total time=   7.9s\n","[CV 2/5] END my_classifier__alpha=129, my_classifier__lambda=59, my_classifier__max_depth=13, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.855) total time=   7.2s\n","[CV 3/5] END my_classifier__alpha=129, my_classifier__lambda=59, my_classifier__max_depth=13, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=   6.9s\n","[CV 4/5] END my_classifier__alpha=129, my_classifier__lambda=59, my_classifier__max_depth=13, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.862) total time=   6.9s\n","[CV 5/5] END my_classifier__alpha=129, my_classifier__lambda=59, my_classifier__max_depth=13, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.856) total time=   6.9s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=72, my_classifier__lambda=167, my_classifier__max_depth=15, my_classifier__n_estimators=51, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  13.4s\n","[CV 2/5] END my_classifier__alpha=72, my_classifier__lambda=167, my_classifier__max_depth=15, my_classifier__n_estimators=51, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=  13.4s\n","[CV 3/5] END my_classifier__alpha=72, my_classifier__lambda=167, my_classifier__max_depth=15, my_classifier__n_estimators=51, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.881) total time=  13.2s\n","[CV 4/5] END my_classifier__alpha=72, my_classifier__lambda=167, my_classifier__max_depth=15, my_classifier__n_estimators=51, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=  13.4s\n","[CV 5/5] END my_classifier__alpha=72, my_classifier__lambda=167, my_classifier__max_depth=15, my_classifier__n_estimators=51, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=  13.3s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=85, my_classifier__lambda=87, my_classifier__max_depth=17, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.860) total time=  10.7s\n","[CV 2/5] END my_classifier__alpha=85, my_classifier__lambda=87, my_classifier__max_depth=17, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.858) total time=  10.5s\n","[CV 3/5] END my_classifier__alpha=85, my_classifier__lambda=87, my_classifier__max_depth=17, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.881) total time=  10.6s\n","[CV 4/5] END my_classifier__alpha=85, my_classifier__lambda=87, my_classifier__max_depth=17, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  10.7s\n","[CV 5/5] END my_classifier__alpha=85, my_classifier__lambda=87, my_classifier__max_depth=17, my_classifier__n_estimators=36, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.861) total time=  10.6s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=176, my_classifier__lambda=199, my_classifier__max_depth=17, my_classifier__n_estimators=54, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  14.8s\n","[CV 2/5] END my_classifier__alpha=176, my_classifier__lambda=199, my_classifier__max_depth=17, my_classifier__n_estimators=54, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.863) total time=  14.9s\n","[CV 3/5] END my_classifier__alpha=176, my_classifier__lambda=199, my_classifier__max_depth=17, my_classifier__n_estimators=54, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.885) total time=  14.8s\n","[CV 4/5] END my_classifier__alpha=176, my_classifier__lambda=199, my_classifier__max_depth=17, my_classifier__n_estimators=54, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.877) total time=  16.2s\n","[CV 5/5] END my_classifier__alpha=176, my_classifier__lambda=199, my_classifier__max_depth=17, my_classifier__n_estimators=54, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.870) total time=  15.9s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=195, my_classifier__lambda=163, my_classifier__max_depth=14, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.856) total time=   7.4s\n","[CV 2/5] END my_classifier__alpha=195, my_classifier__lambda=163, my_classifier__max_depth=14, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.856) total time=   7.3s\n","[CV 3/5] END my_classifier__alpha=195, my_classifier__lambda=163, my_classifier__max_depth=14, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.868) total time=   7.4s\n","[CV 4/5] END my_classifier__alpha=195, my_classifier__lambda=163, my_classifier__max_depth=14, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.860) total time=   7.4s\n","[CV 5/5] END my_classifier__alpha=195, my_classifier__lambda=163, my_classifier__max_depth=14, my_classifier__n_estimators=27, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.857) total time=   7.4s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=127, my_classifier__lambda=129, my_classifier__max_depth=17, my_classifier__n_estimators=12, preprocessor__num__imputer__strategy=mean;, score=(train=0.997, test=0.820) total time=   4.5s\n","[CV 2/5] END my_classifier__alpha=127, my_classifier__lambda=129, my_classifier__max_depth=17, my_classifier__n_estimators=12, preprocessor__num__imputer__strategy=mean;, score=(train=0.996, test=0.830) total time=   4.5s\n","[CV 3/5] END my_classifier__alpha=127, my_classifier__lambda=129, my_classifier__max_depth=17, my_classifier__n_estimators=12, preprocessor__num__imputer__strategy=mean;, score=(train=0.997, test=0.854) total time=   4.5s\n","[CV 4/5] END my_classifier__alpha=127, my_classifier__lambda=129, my_classifier__max_depth=17, my_classifier__n_estimators=12, preprocessor__num__imputer__strategy=mean;, score=(train=0.997, test=0.838) total time=   4.6s\n","[CV 5/5] END my_classifier__alpha=127, my_classifier__lambda=129, my_classifier__max_depth=17, my_classifier__n_estimators=12, preprocessor__num__imputer__strategy=mean;, score=(train=0.997, test=0.827) total time=   4.5s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=64, my_classifier__lambda=184, my_classifier__max_depth=18, my_classifier__n_estimators=94, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  23.0s\n","[CV 2/5] END my_classifier__alpha=64, my_classifier__lambda=184, my_classifier__max_depth=18, my_classifier__n_estimators=94, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  22.4s\n","[CV 3/5] END my_classifier__alpha=64, my_classifier__lambda=184, my_classifier__max_depth=18, my_classifier__n_estimators=94, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.882) total time=  23.1s\n","[CV 4/5] END my_classifier__alpha=64, my_classifier__lambda=184, my_classifier__max_depth=18, my_classifier__n_estimators=94, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.869) total time=  23.3s\n","[CV 5/5] END my_classifier__alpha=64, my_classifier__lambda=184, my_classifier__max_depth=18, my_classifier__n_estimators=94, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  23.3s\n","Fitting 5 folds for each of 1 candidates, totalling 5 fits\n","[CV 1/5] END my_classifier__alpha=105, my_classifier__lambda=116, my_classifier__max_depth=13, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.873) total time=  18.3s\n","[CV 2/5] END my_classifier__alpha=105, my_classifier__lambda=116, my_classifier__max_depth=13, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.872) total time=  19.5s\n","[CV 3/5] END my_classifier__alpha=105, my_classifier__lambda=116, my_classifier__max_depth=13, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.882) total time=  21.1s\n","[CV 4/5] END my_classifier__alpha=105, my_classifier__lambda=116, my_classifier__max_depth=13, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  20.1s\n","[CV 5/5] END my_classifier__alpha=105, my_classifier__lambda=116, my_classifier__max_depth=13, my_classifier__n_estimators=82, preprocessor__num__imputer__strategy=mean;, score=(train=1.000, test=0.871) total time=  18.3s\n","best score 0.8741409612894714\n","best score OrderedDict([('my_classifier__alpha', 130), ('my_classifier__lambda', 151), ('my_classifier__max_depth', 16), ('my_classifier__n_estimators', 68), ('preprocessor__num__imputer__strategy', 'mean')])\n"]}]},{"cell_type":"markdown","source":["###thoughts and observations for trial 7\n","\n","In the end after trying to combat the overfitting issue, the standardization hyper parameters did not help in reducing overfitting. The training accuries remained at 100%. In the future even more tuning to parameters such as finding lower values for max depth and lower values for the parameter colsample_bytree have been seen to reduce overfitting in XGBoost. "],"metadata":{"id":"aVjCXfn4XS4j"}},{"cell_type":"markdown","source":["# **Questions**"],"metadata":{"id":"QAIM3DMzAR2A"}},{"cell_type":"markdown","source":["- 🌈 Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?\n","\n","In a binary classificaiton task the outcome is to find the probability of an outcome occurring. With linear regression your prediction is an absolute numberm this can range outside of 0 or 1. Linear regression is more suitable for predicting continuous values, as its prediction output can be any real number. Logistic regression is more suitable for classificaiton problems, as it predicts values between 0 and 1. \n","\n","- 🌈What's a decision tree and how it is different to a logistic regression model?\n","\n","Decision trees are a supervised algorithm that continuously splits the data based on certian model parameters. Decision trees can be considered white box models as they are transparent with their decision making process. Decision trees work by splitting the space into subregions gradually getting smaller and smaller. Logistic regression works by dividing the space into exactly two regions by fitting a single line. \n","\n","\n","Comparison Study of GridSearchCV and RandomSearshCV\n","GridSearchCV\n","RandomSearshCV\n","Grid is well-defined\tGrid is not well defined\n","Discrete values for HP-params\tContinuos values and Statistical distribution\n","Defined size for Hyperparameter space\tNo such a restriction\n","Picks of the best combination from HP-Space\tPicks up the samples from HP-Space\n","Samples are not created\tSamples are created and specified by the range and n_iter\n","Low performance than RSCV\tBetter performance and result\n","Guided flow to search for the best combination\tThe name itself says that, no guidance.\n","The blow pictorial representation would give you the best understanding of GridSearchCV and RandomSearshCV.\n","\n","\n","- 🌈What's the difference between grid search and random search?\n","\n","grid search defines a grid of hyperparameter values, the algorithm searches this space to train models for every possible combination of hyperparameter vlaues. Random search instead of giving a set of hyper-parameter values, you give a distribution for each hyper-parameter from which the algorithm will sample from. \n","\n","- 🌈What's the difference between bayesian search and random search?\n","\n","the main difference between bayesian search and random search is that bayesian search uses results from previous iterations to decide what the next set of hyper-parameter values should be. "],"metadata":{"id":"0e6yVmafyuHt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueIkkTQ3NlB_","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1666623470282,"user_tz":240,"elapsed":5,"user":{"displayName":"Dusty Pulver","userId":"16342991633441224682"}},"outputId":"b175bdc3-7602-4ee3-c514-901bf7635be2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id     match\n","0      934  0.042389\n","1     6539  0.625355\n","2     6757  0.267338\n","3     2275  0.017560\n","4     1052  0.033083\n","...    ...       ...\n","2464  7982  0.204257\n","2465  7299  0.609881\n","2466  1818  0.032152\n","2467   937  0.015992\n","2468  6691  0.005927\n","\n","[2469 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-59e40a7d-4db2-4d5a-9e73-81f39be740ac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>match</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>934</td>\n","      <td>0.042389</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6539</td>\n","      <td>0.625355</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6757</td>\n","      <td>0.267338</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2275</td>\n","      <td>0.017560</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1052</td>\n","      <td>0.033083</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2464</th>\n","      <td>7982</td>\n","      <td>0.204257</td>\n","    </tr>\n","    <tr>\n","      <th>2465</th>\n","      <td>7299</td>\n","      <td>0.609881</td>\n","    </tr>\n","    <tr>\n","      <th>2466</th>\n","      <td>1818</td>\n","      <td>0.032152</td>\n","    </tr>\n","    <tr>\n","      <th>2467</th>\n","      <td>937</td>\n","      <td>0.015992</td>\n","    </tr>\n","    <tr>\n","      <th>2468</th>\n","      <td>6691</td>\n","      <td>0.005927</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2469 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59e40a7d-4db2-4d5a-9e73-81f39be740ac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-59e40a7d-4db2-4d5a-9e73-81f39be740ac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-59e40a7d-4db2-4d5a-9e73-81f39be740ac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}],"source":["# prepare submission:\n","submission = pd.DataFrame()\n","submission['id'] = data_test['id']\n","submission['match'] = bayes_search_lambda.predict_proba(data_test)[:,1]\n","submission.to_csv('bayes_search_lambda.csv', index=False)\n","submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9deoondNlCA"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}